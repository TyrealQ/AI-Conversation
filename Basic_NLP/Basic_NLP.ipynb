{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "SAj0xz4y0l4I"
      ],
      "authorship_tag": "ABX9TyN45ZjVLFWpyJEFkFZ3x/Fh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TyrealQ/AI-Conversation/blob/main/Basic_NLP/Basic_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Overview**\n",
        "\n",
        "This codebook provides a collection of code and detailed guides for fundamental Natural Language Processing (NLP) applications using Hugging Face's Transformers library. It covers essential techniques such as sentiment analysis, text summarization, and named entity recognition. Each section includes step-by-step explanations, code snippets, and best practices to help users effectively implement transformer-based models for various NLP tasks. Ideal for beginners and intermediate users, this resource serves as a practical reference for leveraging state-of-the-art NLP models with minimal effort.\n",
        "\n",
        "Code authored by: **[Tyreal Qian](https://tyrealq.github.io/)**"
      ],
      "metadata": {
        "id": "dZ5kLaOryUQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "Ms63jKHY3AR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install tqdm\n",
        "!pip install vaderSentiment\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "2pHtAN-ov_OA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "822f249f-47b7-4f86-bb55-2f4e763322e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2025.1.31)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use transformers to load pre-trained models for NLP tasks\n",
        "from transformers import pipeline\n",
        "\n",
        "# Use VADER for lexicon-based sentiment analysis\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Use datasets to easily load and preprocess NLP datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Use tqdm to display progress bars for loops and processing tasks\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Use sklearn for evaluating model performance (accuracy, precision, recall, F1-score)\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "I0twZOQWSzQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sentiment Analysis**\n",
        "Sentiment Analysis is an NLP task that determines the emotional tone of a text. Approaches include:\n",
        "\n",
        "- Lexicon-based → Uses predefined word lists with sentiment scores (e.g., VADER, SentiWordNet).\n",
        "- Machine Learning → Employs classifiers like Naïve Bayes or SVM trained on labeled sentiment data.\n",
        "- Deep Learning → Utilizes models like LSTMs, CNNs, and Transformer-based architectures (e.g., BERT, RoBERTa) for more nuanced analysis.\n",
        "\n",
        "Common categories:\n",
        "- Positive → e.g., *Dr. Q is amazing!*\n",
        "- Negative → e.g., *I hated Dr. Q.*\n",
        "- Neutral → e.g., *Dr. Q was okay, nothing special.*"
      ],
      "metadata": {
        "id": "QDJaABoOyOd2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HF Pipeline\n",
        "\n",
        "- [Hugging Face Text Classification Models](https://huggingface.co/models?pipeline_tag=text-classification&sort=trending)<br> A collection of models that can analyze and classify text. These models can determine if a review is positive or negative, detect spam, or recognize emotions in text.\n",
        "\n",
        "- [Hugging Face Transformers Documentation](https://huggingface.co/docs/transformers/en/index)<br>A user-friendly guide for using Hugging Face's \"Transformers\" library. It provides pre-trained models for tasks like text understanding, translation, and more—helping developers apply AI without needing to train models from scratch.\n",
        "\n"
      ],
      "metadata": {
        "id": "SAj0xz4y0l4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load sentiment analysis models\n",
        "pipe1 = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
        "pipe2 = pipeline(\"text-classification\", model=\"clapAI/modernBERT-base-multilingual-sentiment\")\n",
        "pipe3 = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to convert VADER scores to categorical labels\n",
        "def vader_to_label(text):\n",
        "    scores = pipe3.polarity_scores(text)\n",
        "    compound = scores[\"compound\"]\n",
        "    label = \"negative\" if compound < -0.05 else \"neutral\" if -0.05 <= compound <= 0.05 else \"positive\"\n",
        "    return {\"label\": label, \"compound score\": compound}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNABZ3QJ1Boo",
        "outputId": "b62c093b-6c32-463d-a9bd-6dc00549f6ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EN: Dr. Q is the best!\n",
        "# ZH: Dr. Q 是最棒的！\n",
        "# FR: Dr. Q est le meilleur !\n",
        "# ES: ¡Dr. Q es el mejor!\n",
        "# JA: Dr. Q は最高です！\n",
        "# KO: Dr. Q가 최고예요!\n",
        "\n",
        "text = \"Dr. Q is the best!\"\n",
        "\n",
        "# Get results from each model\n",
        "result1 = pipe1(text)\n",
        "result2 = pipe2(text)\n",
        "result3 = vader_to_label(text)\n",
        "\n",
        "# Print results\n",
        "print(\"RoBERTa:\", result1)\n",
        "print(\"modernBERT:\", result2)\n",
        "print(\"VADER:\", result3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f63OzOdgTRcP",
        "outputId": "dad004aa-57b0-4183-c11f-8fbad6a7baa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RoBERTa: [{'label': 'neutral', 'score': 0.7717776298522949}]\n",
            "modernBERT: [{'label': 'positive', 'score': 0.9238993525505066}]\n",
            "VADER: {'label': 'neutral', 'compound score': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: [tyrealqian/Stadium_RoBERTa_eval](https://huggingface.co/datasets/tyrealqian/Stadium_RoBERTa_eval)\n",
        "\n",
        "This dataset is hosted on HF and is designed for evaluating text classification models in the context of college football stadium reviews. It contains text data along with corresponding labels, making it useful for testing and benchmarking models.\n"
      ],
      "metadata": {
        "id": "eR2iGl0x8Ogj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "ds = load_dataset(\"tyrealqian/TGL-content-classification\")\n",
        "\n",
        "# Check the dataset structure\n",
        "print(ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcrpwF1L6w42",
        "outputId": "07f897ee-59d5-488b-86fc-c595e5f2c348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 500\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracts the 'text' column as a list\n",
        "texts = ds[\"test\"][\"text\"]\n",
        "\n",
        "# Display first 10 samples\n",
        "print(texts[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oixPIrD293dn",
        "outputId": "cd5bd558-5918-4d88-fb00-f778ef025c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['They pack them in there tight', 'biggest and baddest football stadium on the land', 'clean restrooms', 'Bring a water bottle - you can bring in an empty bottle and fill from the water fountain', 'Beaver stadium is a treat to watch a football game', 'As you approach the stadium, it is unimpressive and un-inspiring', 'The best place to be on a fall Saturday even in the rain', 'the players', 'The flea market is once a month, so there are only 1 or 2 months when you should not go', 'I have been asked many times by friends, some who are season ticket holders and others first-time game attendees, to offer up some examples of things to shoot in/around the stadium']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process Transformer models in batches with progress bars\n",
        "def get_transformer_predictions(pipe, texts, model_name, batch_size=10):\n",
        "    results = []\n",
        "    with tqdm(total=len(texts), desc=f\"Processing {model_name}\", leave=True) as pbar:\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch = texts[i : i + batch_size]\n",
        "            batch_results = pipe(batch)\n",
        "            results.extend(batch_results)\n",
        "            pbar.update(len(batch))\n",
        "    return results\n",
        "\n",
        "# Run models on the first 10 texts\n",
        "texts_to_process = texts[:10]\n",
        "results1 = get_transformer_predictions(pipe1, texts_to_process, \"RoBERTa\")\n",
        "results2 = get_transformer_predictions(pipe2, texts_to_process, \"modernBERT\")\n",
        "\n",
        "# Process VADER\n",
        "results3 = []\n",
        "with tqdm(total=len(texts_to_process), desc=\"Processing VADER\") as pbar:\n",
        "    for text in texts_to_process:\n",
        "        results3.append(vader_to_label(text))\n",
        "        pbar.update(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGH7hF3-WS81",
        "outputId": "8bacadd6-d4ec-4735-8f8e-dd749b0da1df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing RoBERTa: 100%|██████████| 10/10 [00:00<00:00, 11.66it/s]\n",
            "Processing modernBERT: 100%|██████████| 10/10 [00:01<00:00,  8.44it/s]\n",
            "Processing VADER: 100%|██████████| 10/10 [00:00<00:00, 7481.81it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display results\n",
        "print(results1)\n",
        "print(results2)\n",
        "print(results3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUkbz4QXZKas",
        "outputId": "4e0ce0d4-d9cf-4255-d8f6-af533970df9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'neutral', 'score': 0.7514070272445679}, {'label': 'negative', 'score': 0.8973892331123352}, {'label': 'neutral', 'score': 0.6642183065414429}, {'label': 'neutral', 'score': 0.8351932168006897}, {'label': 'positive', 'score': 0.9491835236549377}, {'label': 'negative', 'score': 0.8138197064399719}, {'label': 'positive', 'score': 0.9694348573684692}, {'label': 'neutral', 'score': 0.794072687625885}, {'label': 'neutral', 'score': 0.5529199242591858}, {'label': 'neutral', 'score': 0.856681764125824}]\n",
            "[{'label': 'neutral', 'score': 0.5236957669258118}, {'label': 'negative', 'score': 0.4571104645729065}, {'label': 'neutral', 'score': 0.5250078439712524}, {'label': 'positive', 'score': 0.4813658595085144}, {'label': 'neutral', 'score': 0.48322004079818726}, {'label': 'negative', 'score': 0.671226978302002}, {'label': 'positive', 'score': 0.9283379316329956}, {'label': 'positive', 'score': 0.7350207567214966}, {'label': 'positive', 'score': 0.5722318291664124}, {'label': 'neutral', 'score': 0.7744237184524536}]\n",
            "[{'label': 'neutral', 'compound score': 0.0}, {'label': 'neutral', 'compound score': 0.0}, {'label': 'positive', 'compound score': 0.4019}, {'label': 'negative', 'compound score': -0.2023}, {'label': 'positive', 'compound score': 0.4019}, {'label': 'negative', 'compound score': -0.34}, {'label': 'positive', 'compound score': 0.6369}, {'label': 'neutral', 'compound score': 0.0}, {'label': 'neutral', 'compound score': 0.0}, {'label': 'positive', 'compound score': 0.1779}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results for comparison\n",
        "for i, text in enumerate(texts_to_process):\n",
        "    print(f\"\\nText: {text}\")\n",
        "    print(f\"RoBERTa: {results1[i]['label']}; Confidence: {results1[i]['score']:.3f}\")\n",
        "    print(f\"modernBERT: {results2[i]['label'].lower()}; Confidence: {results2[i]['score']:.3f}\")\n",
        "    print(f\"VADER: {results3[i]['label']}; Compound: {results3[i]['compound score']:.3f}\")\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quYD65qiXcLA",
        "outputId": "fc48fff4-e1e7-4488-d6e4-9a08c8460c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text: They pack them in there tight\n",
            "RoBERTa: neutral; Confidence: 0.751\n",
            "modernBERT: neutral; Confidence: 0.524\n",
            "VADER: neutral; Compound: 0.000\n",
            "------------------------------------------------------------\n",
            "\n",
            "Text: biggest and baddest football stadium on the land\n",
            "RoBERTa: negative; Confidence: 0.897\n",
            "modernBERT: negative; Confidence: 0.457\n",
            "VADER: neutral; Compound: 0.000\n",
            "------------------------------------------------------------\n",
            "\n",
            "Text: clean restrooms\n",
            "RoBERTa: neutral; Confidence: 0.664\n",
            "modernBERT: neutral; Confidence: 0.525\n",
            "VADER: positive; Compound: 0.402\n",
            "------------------------------------------------------------\n",
            "\n",
            "Text: Bring a water bottle - you can bring in an empty bottle and fill from the water fountain\n",
            "RoBERTa: neutral; Confidence: 0.835\n",
            "modernBERT: positive; Confidence: 0.481\n",
            "VADER: negative; Compound: -0.202\n",
            "------------------------------------------------------------\n",
            "\n",
            "Text: Beaver stadium is a treat to watch a football game\n",
            "RoBERTa: positive; Confidence: 0.949\n",
            "modernBERT: neutral; Confidence: 0.483\n",
            "VADER: positive; Compound: 0.402\n",
            "------------------------------------------------------------\n",
            "\n",
            "Text: As you approach the stadium, it is unimpressive and un-inspiring\n",
            "RoBERTa: negative; Confidence: 0.814\n",
            "modernBERT: negative; Confidence: 0.671\n",
            "VADER: negative; Compound: -0.340\n",
            "------------------------------------------------------------\n",
            "\n",
            "Text: The best place to be on a fall Saturday even in the rain\n",
            "RoBERTa: positive; Confidence: 0.969\n",
            "modernBERT: positive; Confidence: 0.928\n",
            "VADER: positive; Compound: 0.637\n",
            "------------------------------------------------------------\n",
            "\n",
            "Text: the players\n",
            "RoBERTa: neutral; Confidence: 0.794\n",
            "modernBERT: positive; Confidence: 0.735\n",
            "VADER: neutral; Compound: 0.000\n",
            "------------------------------------------------------------\n",
            "\n",
            "Text: The flea market is once a month, so there are only 1 or 2 months when you should not go\n",
            "RoBERTa: neutral; Confidence: 0.553\n",
            "modernBERT: positive; Confidence: 0.572\n",
            "VADER: neutral; Compound: 0.000\n",
            "------------------------------------------------------------\n",
            "\n",
            "Text: I have been asked many times by friends, some who are season ticket holders and others first-time game attendees, to offer up some examples of things to shoot in/around the stadium\n",
            "RoBERTa: neutral; Confidence: 0.857\n",
            "modernBERT: neutral; Confidence: 0.774\n",
            "VADER: positive; Compound: 0.178\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "\n",
        "To assess the performance of the models, we compute several key evaluation metrics: <br><br>\n",
        "\n",
        "- Accuracy: Measures the proportion of correct predictions out of all predictions. It is calculated as:\n",
        "\n",
        "  $$\n",
        "  \\text{Accuracy} = \\frac{\\text{Correct Predictions}}{\\text{Total Predictions}}\n",
        "  $$\n",
        "\n",
        "- Precision: Indicates how many of the predicted positive (or negative/neutral) instances are actually correct. It is defined as:\n",
        "\n",
        "  $$\n",
        "  \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\n",
        "  $$\n",
        "\n",
        "- Recall: Measures the model's ability to correctly identify all relevant instances. It is given by:\n",
        "\n",
        "  $$\n",
        "  \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n",
        "  $$\n",
        "\n",
        "- F1-score: The harmonic mean of precision and recall, balancing both measures. It is computed as:\n",
        "\n",
        "  $$\n",
        "  \\text{F1-score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "  $$\n",
        "\n",
        "<br>Each of these metrics provides insights into the effectiveness of the sentiment models, with a higher score indicating better performance.\n"
      ],
      "metadata": {
        "id": "EFOe9Qli1DEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a dataset\n",
        "dataset = load_dataset(\"tyrealqian/Stadium_RoBERTa_eval\")\n",
        "\n",
        "# Select a sample of 100 texts and corresponding ground-truth labels\n",
        "test_texts = dataset[\"test\"][\"text\"]\n",
        "test_labels = dataset[\"test\"][\"label\"]"
      ],
      "metadata": {
        "id": "UrQm1ROg1FhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display first 10 samples\n",
        "print(test_texts[:10])\n",
        "print(test_labels[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY5pBpLWGOHj",
        "outputId": "f962286e-bcdd-4f5b-cd7c-432791cbbc67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['They pack them in there tight', 'biggest and baddest football stadium on the land', 'clean restrooms', 'Bring a water bottle - you can bring in an empty bottle and fill from the water fountain', 'Beaver stadium is a treat to watch a football game', 'As you approach the stadium, it is unimpressive and un-inspiring', 'The best place to be on a fall Saturday even in the rain', 'the players', 'The flea market is once a month, so there are only 1 or 2 months when you should not go', 'I have been asked many times by friends, some who are season ticket holders and others first-time game attendees, to offer up some examples of things to shoot in/around the stadium']\n",
            "[1, 2, 2, 1, 2, 0, 2, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the sentiment analysis pipeline with the pre-trained models\n",
        "pipe1 = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
        "pipe2 = pipeline(\"text-classification\", model=\"clapAI/modernBERT-base-multilingual-sentiment\")\n",
        "pipe3 = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to convert VADER scores to categorical labels\n",
        "def vader_to_label(text):\n",
        "    score = pipe3.polarity_scores(text)[\"compound\"]\n",
        "    return 0 if score < -0.05 else 1 if -0.05 <= score <= 0.05 else 2  # Negative, Neutral, Positive\n",
        "\n",
        "# Function to get predictions from transformer pipelines\n",
        "def get_transformer_predictions(pipe, texts, model_name):\n",
        "    results = []\n",
        "    for text in tqdm(texts, desc=f\"Processing {model_name}\", leave=True):\n",
        "        results.append(pipe(text)[0])\n",
        "    predicted_labels = [\n",
        "        0 if res['label'].lower() == 'negative' else 1 if res['label'].lower() == 'neutral' else 2\n",
        "        for res in results\n",
        "    ]\n",
        "    return predicted_labels\n",
        "\n",
        "# Generate predictions from all three approaches\n",
        "predicted_labels_roberta = get_transformer_predictions(pipe1, test_texts, \"RoBERTa\")\n",
        "predicted_labels_modernBERT = get_transformer_predictions(pipe2, test_texts, \"modernBERT\")\n",
        "predicted_labels_vader = [vader_to_label(text) for text in tqdm(test_texts, desc=\"Processing VADER\")]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA-uNmrdDWOn",
        "outputId": "f4006f04-eb1e-4eb6-a52d-4f424bb6483d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Processing RoBERTa: 100%|██████████| 500/500 [00:43<00:00, 11.38it/s]\n",
            "Processing modernBERT: 100%|██████████| 500/500 [01:02<00:00,  8.05it/s]\n",
            "Processing VADER: 100%|██████████| 500/500 [00:00<00:00, 28425.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate accuracy, precision, recall, and F1-score\n",
        "def evaluate_model(test_labels, predicted_labels):\n",
        "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        test_labels, predicted_labels, average='weighted', zero_division=1\n",
        "    )\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate all models\n",
        "metrics_roberta = evaluate_model(test_labels, predicted_labels_roberta)\n",
        "metrics_modernBERT = evaluate_model(test_labels, predicted_labels_modernBERT)\n",
        "metrics_vader = evaluate_model(test_labels, predicted_labels_vader)\n",
        "\n",
        "# Print results in a formatted table\n",
        "print(\"\\nModel Performance Comparison:\\n\")\n",
        "print(f\"{'Metric':<15}{'RoBERTa':<12}{'modernBERT':<12}{'VADER':<12}\")\n",
        "print(\"-\" * 45)\n",
        "print(f\"{'Accuracy':<15}{metrics_roberta[0]:<12.3f}{metrics_modernBERT[0]:<12.3f}{metrics_vader[0]:.3f}\")\n",
        "print(f\"{'Precision':<15}{metrics_roberta[1]:<12.3f}{metrics_modernBERT[1]:<12.3f}{metrics_vader[1]:.3f}\")\n",
        "print(f\"{'Recall':<15}{metrics_roberta[2]:<12.3f}{metrics_modernBERT[2]:<12.3f}{metrics_vader[2]:.3f}\")\n",
        "print(f\"{'F1-score':<15}{metrics_roberta[3]:<12.3f}{metrics_modernBERT[3]:<12.3f}{metrics_vader[3]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq_r1pcYMZz0",
        "outputId": "9b20af63-7f07-4fb2-a5d0-2d31707309ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance Comparison:\n",
            "\n",
            "Metric         RoBERTa     modernBERT  VADER       \n",
            "---------------------------------------------\n",
            "Accuracy       0.784       0.594       0.664\n",
            "Precision      0.835       0.751       0.728\n",
            "Recall         0.784       0.594       0.664\n",
            "F1-score       0.798       0.633       0.684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next: Fine-tune a text classification model"
      ],
      "metadata": {
        "id": "fd8ENzVFFXbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Named Entity Recognition (NER)\n",
        "\n",
        "NER is a Natural Language Processing (NLP) task that identifies and classifies entities in text into predefined categories such as:\n",
        "\n",
        "- PER (Person) → e.g., *Dr. Q*\n",
        "- ORG (Organization) → e.g., *NASSM*\n",
        "- LOC (Location) → e.g., *San Diego*\n",
        "- MISC (Miscellaneous) → e.g., *AI*"
      ],
      "metadata": {
        "id": "wcNkl2f41WXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\n",
        "February NASSM Conversations The February installment of NASSM Conversations will dive into something we are all becoming more familiar with daily: AI. This session’s moderators, Drs. Yizhou Tyreal Qian from Louisiana State University and Mike Naraine from Brock University will discuss the various applications of AI in sport management. Date: Monday, March 3, 2-3 pm ET.\n",
        "'''\n",
        "\n",
        "# Load the NER pipeline\n",
        "ner = pipeline(\n",
        "    \"ner\",\n",
        "    model=\"xlm-roberta-large-finetuned-conll03-english\",\n",
        "\n",
        "    # Change model here if needed:\n",
        "    # \"Jean-Baptiste/roberta-large-ner-english\"\n",
        "    # \"xlm-roberta-large-finetuned-conll03-english\"\n",
        "    # \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
        "\n",
        "    aggregation_strategy=\"simple\"  # Define how entities are merged\n",
        "\n",
        "    # Aggregation Strategies:\n",
        "    # \"none\"  -> No aggregation (each token is a separate entity)\n",
        "    # \"simple\" -> Merges consecutive tokens with the same entity type\n",
        "    # \"first\"  -> Keeps only the first token of an entity\n",
        "    # \"max\"    -> Keeps the token with the highest confidence score\n",
        ")"
      ],
      "metadata": {
        "id": "HNCFmIbwNOgB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "634662df-c871-43c0-a6ca-172d73cfaea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-large-finetuned-conll03-english were not used when initializing XLMRobertaForTokenClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpUwfzrwpBRa",
        "outputId": "c457451d-905c-4887-e630-8d6dc16be113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  entity_group     score                      word  start  end\n",
            "0         MISC  0.999851        NASSMConversations     10   29\n",
            "1         MISC  0.999771        NASSMConversations     58   77\n",
            "2         MISC  0.983233                       AI.    149  152\n",
            "3          PER  0.999905          YizhouTyrealQian    185  203\n",
            "4          ORG  0.999970  LouisianaStateUniversity    209  235\n",
            "5          PER  0.999944               MikeNaraine    240  252\n",
            "6          ORG  0.999967           BrockUniversity    258  274\n",
            "7         MISC  0.986315                        AI    316  318\n",
            "8         MISC  0.952088                       ET.    370  373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(ner(text))\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "2rVknw8xpDlB",
        "outputId": "e9c35473-68b9-4161-ef8b-6c2324bea1a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  entity_group     score                        word  start  end\n",
              "0         MISC  0.992500         NASSM Conversations     10   29\n",
              "1         MISC  0.998587         NASSM Conversations     58   77\n",
              "2         MISC  0.983233                          AI    149  151\n",
              "3          PER  0.999790          Yizhou Tyreal Qian    185  203\n",
              "4          ORG  0.999970  Louisiana State University    209  235\n",
              "5          PER  0.999915                Mike Naraine    240  252\n",
              "6          ORG  0.999956            Brock University    258  274\n",
              "7         MISC  0.986315                          AI    316  318\n",
              "8         MISC  0.952088                          ET    370  372"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14a287a9-e5cd-4796-8b34-d8c90afda159\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entity_group</th>\n",
              "      <th>score</th>\n",
              "      <th>word</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MISC</td>\n",
              "      <td>0.992500</td>\n",
              "      <td>NASSM Conversations</td>\n",
              "      <td>10</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MISC</td>\n",
              "      <td>0.998587</td>\n",
              "      <td>NASSM Conversations</td>\n",
              "      <td>58</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MISC</td>\n",
              "      <td>0.983233</td>\n",
              "      <td>AI</td>\n",
              "      <td>149</td>\n",
              "      <td>151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PER</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>Yizhou Tyreal Qian</td>\n",
              "      <td>185</td>\n",
              "      <td>203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ORG</td>\n",
              "      <td>0.999970</td>\n",
              "      <td>Louisiana State University</td>\n",
              "      <td>209</td>\n",
              "      <td>235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>PER</td>\n",
              "      <td>0.999915</td>\n",
              "      <td>Mike Naraine</td>\n",
              "      <td>240</td>\n",
              "      <td>252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ORG</td>\n",
              "      <td>0.999956</td>\n",
              "      <td>Brock University</td>\n",
              "      <td>258</td>\n",
              "      <td>274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>MISC</td>\n",
              "      <td>0.986315</td>\n",
              "      <td>AI</td>\n",
              "      <td>316</td>\n",
              "      <td>318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>MISC</td>\n",
              "      <td>0.952088</td>\n",
              "      <td>ET</td>\n",
              "      <td>370</td>\n",
              "      <td>372</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14a287a9-e5cd-4796-8b34-d8c90afda159')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-14a287a9-e5cd-4796-8b34-d8c90afda159 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-14a287a9-e5cd-4796-8b34-d8c90afda159');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fb8332b2-24c6-40d9-9ffe-7c7d78133d2b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb8332b2-24c6-40d9-9ffe-7c7d78133d2b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fb8332b2-24c6-40d9-9ffe-7c7d78133d2b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b985b8cd-7edb-4560-a3b8-b9bd0ba51468\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b985b8cd-7edb-4560-a3b8-b9bd0ba51468 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"entity_group\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"MISC\",\n          \"PER\",\n          \"ORG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.9863146543502808,\n          0.9985867738723755,\n          0.9999151229858398\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"NASSM Conversations\",\n          \"AI\",\n          \"Brock University\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 10,\n        \"max\": 370,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          316,\n          58,\n          240\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 110,\n        \"min\": 29,\n        \"max\": 372,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          318,\n          77,\n          252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Text Summarization**\n",
        "Text Summarization condenses long text into a shorter version while retaining key information. Approaches include:  \n",
        "\n",
        "- Extractive Summarization → Selects the most important sentences from the text (e.g., TextRank, LexRank).  \n",
        "- Abstractive Summarization → Generates new sentences to convey the main ideas (e.g., BART, T5).  \n",
        "\n",
        "Examples:  \n",
        "- Original Text: *DeepSeek announced a groundbreaking open-source model, making cutting-edge AI more accessible to everyone and driving innovation across industries.*\n",
        "- Extractive Summary: *DeepSeek announced a groundbreaking model.*\n",
        "- Abstractive Summary: *A new industry-changing model was introduced.*"
      ],
      "metadata": {
        "id": "w4k2P6yH1J0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load text summarization pipeline\n",
        "text_summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    model=\"google/pegasus-xsum\",  # Pre-trained model for summarization\n",
        "\n",
        "    # Change model here if needed:\n",
        "    # \"google/pegasus-xsum\"\n",
        "    # \"philschmid/bart-large-cnn-samsum\"\n",
        "    # \"Falconsai/text_summarization\"\n",
        "\n",
        "    device=-1  # Use GPU (0) for faster processing (-1 for CPU)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6f9sKkfqVQh",
        "outputId": "1906188e-887a-493a-8b2d-089e4a03ec6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text for summarization\n",
        "text = '''\n",
        "The mission of the North American Society for Sport Management (NASSM) is to promote, stimulate, and encourage study, research, scholarly writing, and professional development in the area of sport management. Members of the Society are concerned about the theoretical and applied aspects of management theory and practice specifically related to sport, exercise, dance, and play, as these fields are pursued by all sectors of the population. The Society endeavors to support and cooperate with local, regional, national, and international organizations that have similar purposes and organizes and administers conferences to promote its purposes.\n",
        "'''\n",
        "\n",
        "# Generate summary\n",
        "summary = text_summarizer(\n",
        "    text,\n",
        "    max_length=50,  # Maximum length of the summary\n",
        "    min_length=10,  # Minimum length of the summary\n",
        "    num_beams=4,  # Beam search optimization (higher = better quality, slower speed)\n",
        "    do_sample=False,  # Whether to introduce randomness (False = deterministic summary)\n",
        "    temperature=0.5,  # Controls randomness (only used if do_sample=True; lower = more conservative)\n",
        "    truncation=True,  # Truncate text if too long for the model\n",
        "    clean_up_tokenization_spaces=True  # Remove extra spaces in output\n",
        ")"
      ],
      "metadata": {
        "id": "X-MrGIrhvj2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xweJtaX2ppZG",
        "outputId": "25a099d0-b69f-4854-b4ae-693dcdacb185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'summary_text': 'The North American Society for Sport Management (NASSM) is a not-for-profit society with members in the United States, Canada, and Mexico.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print summarized text\n",
        "print(summary[0][\"summary_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7leECliVpoNw",
        "outputId": "20c5588f-009f-4514-9eba-7024c34823f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The North American Society for Sport Management (NASSM) is a not-for-profit society with members in the United States, Canada, and Mexico.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Topic Modeling**\n",
        "Topic Modeling is an NLP technique for discovering hidden themes in a collection of texts. Approaches include:\n",
        "\n",
        "- Traditional Methods → Uses probabilistic models like Latent Dirichlet Allocation (LDA) and Non-Negative Matrix Factorization (NMF) to cluster words into topics.\n",
        "- BERTopic → A more advanced method leveraging BERT embeddings, clustering algorithms (e.g., UMAP, HDBSCAN), and TF-IDF representations for more coherent and interpretable topic extraction.\n",
        "\n",
        "Use cases:\n",
        "- LDA/NMF → Suitable for structured, well-separated topics.\n",
        "- BERTopic → Excels at capturing nuanced, contextual topics in large datasets."
      ],
      "metadata": {
        "id": "ho0nT_Qe4xwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demo: Esports at the 2023 Asian Games  \n",
        "\n",
        "This project applied LLM-enhanced BERTopic modeling to analyze esports stakeholders' perceptions regarding the inclusion of esports as a medal event.\n",
        "\n",
        "Explore the full analysis and demos in this [GitHub Repository](https://github.com/TyrealQ/Twitter-Perceptions-Esports-2023-Asian-Games_HICSS-58)."
      ],
      "metadata": {
        "id": "7B8AyM0E9xVI"
      }
    }
  ]
}