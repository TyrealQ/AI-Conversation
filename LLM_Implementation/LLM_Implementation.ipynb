{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Ka43lJ_KAU8_nsLVZTFrBKWCWnUHLhIj",
      "authorship_tag": "ABX9TyNVhOce6GLt3cv81Oej5qsX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TyrealQ/AI-Conversation/blob/main/LLM_Implementation/LLM_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Overview\n",
        "\n",
        "This comprehensive guide provides code and detailed instructions for implementing OpenAI's GPT models across applications. Each section delivers clear explanations alongside practical code snippets, enabling effective LLM integration. The codebook serves both newcomers and experienced practitioners as a reference resource, helping users leverage language models efficiently to enhance analytical capabilities and streamline workflows.\n",
        "\n",
        "Code authored by: **[Tyreal Qian](https://tyrealq.github.io/)**"
      ],
      "metadata": {
        "id": "px0_QeFkUfRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "7u3iTnKFgYDU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_q5yTdSOUFjh"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "!pip install datasets\n",
        "!pip install openai\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interacting with the operating system\n",
        "import os\n",
        "\n",
        "# System-specific parameters and functions\n",
        "import sys\n",
        "\n",
        "# Handling JSON data\n",
        "import json\n",
        "\n",
        "# Data analysis and manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# Handling large datasets efficiently\n",
        "import datasets\n",
        "\n",
        "# Loading datasets from Hugging Face\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Displaying progress bars in loops\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Handling dictionary default values efficiently\n",
        "from collections import defaultdict\n",
        "\n",
        "# Creating interactive widgets\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Display utilities for IPython environments\n",
        "from IPython.display import display, JSON\n",
        "\n",
        "# Interacting with OpenAI models\n",
        "from openai import OpenAI\n",
        "\n",
        "# Retrieving stored user credentials in Google Colab\n",
        "from google.colab import userdata\n",
        "\n",
        "# OpenAI API keys can be obtained at https://platform.openai.com\n",
        "api_key = userdata.get('GPT_KEY')\n",
        "\n",
        "# Initializing OpenAI client with the retrieved API key\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "I6LUxYmK-UQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aspect-based sentiment analysis (ABSA) for game day experience\n",
        "\n",
        "This project leverages LLMs as an innovative, off-the-shelf solution for ABSA in sports management. It enables scalable and efficient analysis of fan experiences without the complexities of traditional ABSA methods.\n",
        "\n"
      ],
      "metadata": {
        "id": "LI8FgYJjbtnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code and data are available in the [GitHub Repository](https://github.com/TyrealQ/Experience-is-all-you-need_SMR)."
      ],
      "metadata": {
        "id": "oo6mREq65Du2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TGL content classification with [GPT-4o](https://platform.openai.com/docs/models/gpt-4o)\n",
        "\n",
        "This script automates the classification of YouTube video metadata to determine its relevance to the TMRW Golf League (TGL) using GPT-4o. It processes an input Excel file containing video details (title, description, and author) and assigns a filter rating based on predefined relevance criteria.\n",
        "\n",
        "### Key Features:\n",
        "\n",
        "- Utilize GPT-4o to analyze textual content and assign a rating from 1 (unrelated) to 5 (perfect match). Assign \"MANUAL\" for ambiguous cases requiring further review.\n",
        "- Identify direct and indirect connections to TGL, including affiliated players, influencers, and events.\n",
        "- Automatically assign a perfect match (5) if the video's author is @TGL.\n",
        "\n",
        "### Co-developer: [Philip Kang](https://scholar.google.com/citations?user=VynUSnwAAAAJ&hl=en)"
      ],
      "metadata": {
        "id": "gl6S6PMJbusR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "ds = load_dataset(\"tyrealqian/TGL_content_classification\")\n",
        "\n",
        "# Check the dataset structure\n",
        "print(ds)"
      ],
      "metadata": {
        "id": "tvSA0lPx0_KA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(ds['train'].to_pandas())\n",
        "df"
      ],
      "metadata": {
        "id": "1poT8quc9Xkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_document(doc_text):  # Define a function to classify a document based on its text input\n",
        "    try:\n",
        "        # Send document text to GPT-4o for classification\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",  # Use GPT-4o model for classification\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",  # Define system instructions\n",
        "                    \"content\": \"You are an expert classifier.\\\n",
        "                    Your task is to evaluate whether the given document text is directly or contextually related to TMRW Golf League (TGL), an innovative golf league in partnership with the PGA TOUR that fuses advanced technology and live action in prime time.\\\n",
        "                    Content can be considered related if it explicitly mentions TGL or indirectly relates through associated players, influencers (e.g., Good Good Golf), events, or highlights (e.g., player shots, funny moments in TGL events).\\\n",
        "                    Special Rule: If the id_author of the video is @TGL, automatically assign a rating of 5 (perfect match) regardless of the content.\\\n",
        "                    Provide a single rating using the following scale:\\\n",
        "                    1 = no match (completely unrelated to TGL or its ecosystem),\\\n",
        "                    2 = weak match (mentions golf but no clear TGL connection),\\\n",
        "                    3 = moderate match (some connection, but TGL is not a key focus),\\\n",
        "                    4 = strong match (clear TGL connection but not exclusively about TGL),\\\n",
        "                    5 = perfect match (explicitly and primarily about TGL, or id_author equals @TGL),\\\n",
        "                    MANUAL = manual check required (unclear cases or possible indirect relevance).\\\n",
        "                    Output must be in valid JSON format with only the key filter_rating. Example: {\\\"filter_rating\\\": 4}.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",  # Provide the document text as user input\n",
        "                    \"content\": f\"{doc_text}\"\n",
        "                }\n",
        "            ],\n",
        "            temperature=0,  # Ensure deterministic results\n",
        "            max_tokens=2048,  # Allow sufficient token space for response\n",
        "            top_p=1,  # Use deterministic sampling\n",
        "            frequency_penalty=0,  # No penalty for frequent words\n",
        "            presence_penalty=0,  # No encouragement for new topics\n",
        "            response_format={\"type\": \"json_object\"}  # Enforce structured JSON output\n",
        "        )\n",
        "\n",
        "        # Parse and validate JSON response\n",
        "        try:\n",
        "            validation = json.loads(response.choices[0].message.content)  # Convert response to JSON\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Invalid JSON response. Defaulting to MANUAL.\")  # Handle malformed responses\n",
        "            validation = {\"filter_rating\": \"MANUAL\"}  # Assign \"MANUAL\" if parsing fails\n",
        "\n",
        "        # Optional debugging prints\n",
        "        print(\"\\nDocument Preview:\")\n",
        "        print(f\"{doc_text[:200]}...\")  # Display first 200 characters of document text\n",
        "        print(\"\\nValidation Result:\")\n",
        "        print(json.dumps(validation, indent=2))  # Pretty-print classification result\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        return json.dumps(validation)  # Return classification result as JSON string\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError processing document: {e}\")  # Handle unexpected errors\n",
        "        return json.dumps({\"filter_rating\": \"MANUAL\"})  # Default to \"MANUAL\" in case of failure\n",
        "\n",
        "# Read input Excel file\n",
        "input_file = ds  # Path to input file\n",
        "output_file = \"/content/drive/MyDrive/DATA/TGL_classified.xlsx\"  # Path to output file\n",
        "\n",
        "try:\n",
        "    print(f\"Reading input file: {input_file}\")\n",
        "    df = pd.read_excel(input_file)  # Load the Excel file into a pandas DataFrame\n",
        "except Exception as e:\n",
        "    print(f\"Error reading input file: {e}\")\n",
        "    exit(1)  # Exit if file read fails\n",
        "\n",
        "# Classify each row with GPT-4o\n",
        "print(\"\\nStarting document classification...\")\n",
        "validations = []  # Initialize an empty list to store classification results\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Classifying Rows\"):  # Iterate through rows with a progress bar\n",
        "    if row['id_author'] == '@TGL':  # Auto-assign rating 5 if author is @TGL\n",
        "        validations.append(json.dumps({\"filter_rating\": 5}))\n",
        "    else:\n",
        "        doc_text = f\"{row['title']} {row['description']}\"  # Combine title and description\n",
        "        result_json_str = classify_document(doc_text)  # Get classification result\n",
        "        validations.append(result_json_str)  # Store result\n",
        "\n",
        "# Parse the returned JSON and store results\n",
        "parsed_validations = [json.loads(v) for v in validations]  # Convert JSON strings to Python objects\n",
        "df['filter_rating'] = [v.get('filter_rating', 'MANUAL') for v in parsed_validations]  # Extract ratings\n",
        "\n",
        "# Save output to a new Excel file\n",
        "try:\n",
        "    df.to_excel(output_file, index=False)  # Save classified results to a new file\n",
        "    print(f\"\\nClassification complete! Results saved to: {output_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving output file: {e}\")\n",
        "    exit(1)  # Exit if file save fails\n",
        "\n",
        "# Optional: Show summary of ratings\n",
        "print(\"\\nRating Summary:\")\n",
        "print(df['filter_rating'].value_counts(dropna=False))  # Display count of each rating category"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MYiGEPxv1K4",
        "outputId": "1adb6d7f-d701-44a4-85b9-8ad4368f490e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading input file: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['video_link', 'title', 'lang', 'author', 'id_author', 'description', 'link_thumbnail', 'tt', 'views', 'likes', 'comments', 'duration', 'type_video'],\n",
            "        num_rows: 33\n",
            "    })\n",
            "})\n",
            "Error reading input file: Invalid file path or buffer object type: <class 'datasets.dataset_dict.DatasetDict'>\n",
            "\n",
            "Starting document classification...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying Rows:  12%|█▏        | 4/33 [00:01<00:09,  2.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "TGL: Tiger Woods’ Revolutionary Golf League - Everything You Need to Know! Join us as we dive into TGL (Tomorrow’s Golf League), the exciting new golf league created by Tiger Woods! 🏌️‍♂️✨ In this vid...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 5\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  15%|█▌        | 5/33 [00:01<00:10,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "CLUTCH PUTT ⛳️ Justin Rose wins the hole for the Los Angeles Golf Club 🥶 | TGL on ESPN Watch as Justin Rose nails a 14-foot putt to give the Los Angeles Golf Club the win on hole 8 over Tiger Woods an...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 5\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  27%|██▋       | 9/33 [00:06<00:21,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "Tiger Woods couldn’t believe Ludvig Åberg's 32-foot birdie putt | TGL on ESPN Tiger Woods loves Ludvig Åberg's 32-foot birdie putt to win Hole 5 for The Bay Golf Club at the inaugural TGL event.\n",
            "\n",
            "✔️ S...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 5\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  30%|███       | 10/33 [00:07<00:20,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "타이거우즈 맥길로이가 공동제작한 초대형 스크린골프리그 TGL이 시작된다 타이거우즈 맥길로이가 공동제작한 초대형 스크린골프리그 TGL이 시작됩니다, 언제 시작되고 관전포인트는 무엇일까요?...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 5\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  33%|███▎      | 11/33 [00:08<00:18,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "타이거 우즈와 로리 맥길로이가 스크린골프를?? TGL 어떻게 보셨나요?? #TGL #스크린골프 #로리맥길로이스크린골프...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 5\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  36%|███▋      | 12/33 [00:08<00:16,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "지금껏 아무도 공개하지 않았던 TGL의 모든것! 타이거우즈의 새로운 클럽, 공인구, 캐디, 그리고 놓치지 말아야 할 핫 한 경기 일정까지 모두 정리해봤습니다. 마침내 다가온 TGL리그에 많은 기대감이 모아지고 있습니다. 스크린 골프도 타이거우즈가 하면 다르다는 저의 TGL 컨텐츠들은 그동안 많은 관심을 받아 왔죠. 출범은 앞둔 TGL에 대해 지금까지 공개 ...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 5\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  39%|███▉      | 13/33 [00:09<00:14,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "TGL Stadium Exclusive Technology Tour We got a secret first look at TGL new Sofi Stadium. Thanks to @fullswinggolf for bring us along. \n",
            "\n",
            "Don't miss out! Book a FREE 30-minute golf session at The Back ...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 4\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  42%|████▏     | 14/33 [00:10<00:14,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "Euro Truck Simulator 2 (1.53) New Man TGL 2022 by Gaming ModdinG Delivery to Sweden + DLC's & Mods Euro Truck Simulator 2 (1.53) \n",
            "\n",
            "New Man TGL 2022 by Gaming ModdinG Delivery to Sweden Promods map v2....\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 1\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  45%|████▌     | 15/33 [00:11<00:13,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "Was the Inaugural TGL Match In-Person Worth It? (My Honest Experience) I went to the Inaugural TGL match on my own dime and I wanted to share my experience on whether or not it was worth it. Let me kn...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 5\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  48%|████▊     | 16/33 [00:13<00:20,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "The Good, The Bad, and The Ugly: TGL's Opening Night Check out our merch here: https://store.barstoolsports.com/collections/fore-play\n",
            "\n",
            "Download the Barstool Golf Time App: https://beacons.ai/foreplayp...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 4\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  52%|█████▏    | 17/33 [00:14<00:17,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "What Happens if the TGL is a MASSIVE Success? What will happen to the PGA Tour if the TGL is a massive hit? \n",
            "7 Diamonds Clothing ▶ https://www.7diamonds.com/\n",
            "Use Code: MSG15\n",
            "\n",
            "SkyTrak Here ▶ https://sk...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 4\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  55%|█████▍    | 18/33 [00:14<00:14,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "TGL리그에 맞선 골프존의 신규 전략! 시티골프 그리고 다가오는 골프존 투어에 대해 자세하게 정리했습니다. 골프존이 중국에서 새롭게 선보인 시티골프에 이어, 골프 본고장을 직접 공략하는 새로운 리그를 준비중인데요. TGL에 맞선 골프존의 새로운 전략인 시티골프의 첫번째 대회 내용과 새로운 리그는 무엇인지 자세히 알아보겠습니다.\n",
            "\n",
            "Time Stamp\n",
            "00:0...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 2\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  58%|█████▊    | 19/33 [00:15<00:12,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "[TGL]타이거우즈X로리맥길로이, 경기 2시간 컷! 스크린+필드의 끝판왕이 온다 이번 소식은 우리의 ‘골프 황제’ 타이거 우즈와 로리 맥길로이가 출범하는 스크린 골프 리그인 TGL에 대한 소식인데요. TGL은 지난 1월 출범 예정이었으나, 대회장 지붕이 붕괴되는 사고로 인해 1년 연기되었습니다. \n",
            "\n",
            "연기된 만큼 더욱더 TGL에 대한 관심이 고조되고 있는데요...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 5\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  61%|██████    | 20/33 [00:16<00:11,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "[TGL골프] 타이거우즈, 맥길로이가 만든  PGA 스크린골프? TGL 골프에 관한 모든 것 구독과 좋아요는 영상 제작에 정말, 정말 큰 힘이 됩니다!\n",
            "\n",
            "==============================================\n",
            "\n",
            "여러분, 우리시간으로 1월 8일 오전 11시에 타이거우즈가 만든 스크린골프,\n",
            "PGA투어 선수들이 모여 경기하는 TGL ...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 5\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  67%|██████▋   | 22/33 [00:17<00:07,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "‘Hello, new world.’ Tiger Woods reacts to best career moments in PGA TOUR Studio 82-time PGA TOUR winner Tiger Woods gets an immersive experience at the recently opened PGA TOUR Studios, a cutting-edg...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 2\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  70%|██████▉   | 23/33 [00:18<00:07,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "골프존 최고의 위기! 타이거 우즈가 만든 스크린골프 리그 TGL 출범과 앞으로 골프존의 방향을 예측해봤습니다. 골프존에서 많은 시간동안 준비한 골프존 투비전NX가 출시되었죠.\n",
            "사실적인 그래픽과 UI, 그리고 더욱 몰입감 있는 경기 운영과 대형 터치모니터가 인상적이었지만... 이러한 변화는 바로 새로운 스크린 골프 리그인 TGL에 대비한 골프존의 정책이라고 ...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 5\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  73%|███████▎  | 24/33 [00:18<00:06,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "타이거우즈의 스크린골프리그 TGL의 연이은 악재 발생! 과연 TGL을 만나볼 수 있을까? 타이거우즈와 로리 맥길로이의 TGL 리그와 골프존 투비전 NX관련 영상에 관심이 많습니다.\n",
            "현재까지 진행된 TGL의 주요 경기운영 내역과 각종 악재 소식들을 자세하게 정리해보았습니다.\n",
            "\n",
            "\n",
            "Time Stamp\n",
            "00:00 인트로 \n",
            "00:20 상당히 순조로웠던 TGL 출범\n",
            "...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 5\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  76%|███████▌  | 25/33 [00:19<00:05,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "TGL경기방식과 이해할 수 없는 이상한 규칙들 TGL 골프 리그 개막이 얼마 안 남았습니다. 골프를 즐기는 완전히 새로운 방식을 선 보이겠다고 야심차게 출발 하는데요. TGL 리그가 일반 골프와 다른 경기 운영 방식과 이해할 수 없는 이상한 규착들에 대해서 살펴 보겠습니다....\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 5\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  79%|███████▉  | 26/33 [00:20<00:05,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "다가오는 TGL과 풀 스윙 스크린골프! 골프존이 준비한 회심의 역작! 하이브리드 골프 리그에 대해 예상해보았습니다. 지난 영상에서 TGL과 골프존 투비전 NX에 대한 관심이 뜨거웠습니다.\n",
            "오늘은 지난번 영상에서 다루지 않았던 TGL의 기술을 골프존과 비교하고, 댓글 중 가장 궁금해 하셨던 부분들을 다뤄보도록 하겠습니다.\n",
            "\n",
            "* 해당 영상 중 저작권 관련 일부...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 4\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  82%|████████▏ | 27/33 [00:21<00:04,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "新時代のゴルフリーグ「TGL」がいよいよ開幕！ルールは？場所は？出場者は？まとめてチェック！【ゴルフ】 新時代ゴルフリーグ・TGL\n",
            "1月8日の開幕戦「ニューヨーク vs. ベイ」の視聴はこちらから↓\n",
            "https://video.unext.jp/livedetail/LIV0000007451...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 5\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  85%|████████▍ | 28/33 [00:21<00:03,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "타이거 우즈의 TGL에 맞선 골프존의 비밀 전략! 드디어 공개된 시티골프의 주요 내용을 정리해봤습니다. 타이거 우즈와 로리 맥길로이의 TGL출범을 앞두고 골프존이 이에 맞서 그동안 비밀리에 준비한 전략이 드디어 공개되었습니다.\n",
            "새로운 형태의 골프존의 스크린 골프는 무엇이고, TGL과는 어떻게 다른지 꼼꼼하게 정리해봤습니다. \n",
            "\n",
            "Time Stamp\n",
            "00:00...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 4\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  88%|████████▊ | 29/33 [00:22<00:02,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "罗里·麦克罗伊奢华生活方式 Rory Mcllroy Luxurious Lifestyle #golf #golfswing\n",
            "\n",
            "Rory McIlroy, the Irish professional golfer, has a net worth of $170 million. Rory McIlroy, one of the most successful golfers in the w...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 2\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  91%|█████████ | 30/33 [00:23<00:02,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "Does Netflix Want in on Live Sports? - PGA Tour, Formula 1 in \"Netflix Cup\" | The First Cut Podcast #golf #pgatour #formula1 #netflixcup #netflix \n",
            "\n",
            "The PGA Tour and Formula 1 will be involved in one o...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 2\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  94%|█████████▍| 31/33 [00:23<00:01,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "Jon Rahm's PLEA To Allow Rebels To Compete In The Tournament.. Jon Rahm's PLEA To Allow Rebels To Compete In The Tournament..\n",
            "\n",
            "Welcome back to Sport Shock. Bit by bit, day by day, the world’s best gol...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 2\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifying Rows:  97%|█████████▋| 32/33 [00:24<00:00,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "The Good Good Hickory Clubs Major Thanks to SoFi for sponsoring the video! Click here to sign-up for SoFi Checking and Savings!\n",
            "► https://sofi.com/goodgood\n",
            "\n",
            "Our Apparel ► https://goodgoodgolf.com/\n",
            "\n",
            "Th...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 3\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying Rows: 100%|██████████| 33/33 [00:25<00:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document Preview:\n",
            "CURRENT AFFAIRS for BANKING EXAMS: 7th January, 2025 with SHOTS Stay updated with the most important Current Affairs for Banking Exams of 7th January, 2025  with SHOTS - Short Highlights of Top Storie...\n",
            "\n",
            "Validation Result:\n",
            "{\n",
            "  \"filter_rating\": 1\n",
            "}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification complete! Results saved to: /content/drive/MyDrive/DATA/TGL_classified.xlsx\n",
            "\n",
            "Rating Summary:\n",
            "filter_rating\n",
            "5    20\n",
            "4     5\n",
            "2     5\n",
            "1     2\n",
            "3     1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df1 = pd.read_excel(\"/content/drive/MyDrive/DATA/TGL_classified.xlsx\")\n",
        "\n",
        "# Select only the required columns\n",
        "df1 = df1[[\"title\", \"id_author\", \"description\", \"filter_rating\"]]\n",
        "\n",
        "# Adjust pandas display settings to show full text\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Sort ds1 by 'filter_rating' in descending order\n",
        "df1 = df1.sort_values(by=\"filter_rating\", ascending=False)\n",
        "\n",
        "# Display the filtered and sorted DataFrame\n",
        "df1"
      ],
      "metadata": {
        "id": "C3TembUfaGja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Major Takeaways\n",
        "\n",
        "- Use LLMs as intelligent assistants for scalable data analysis.\n",
        "\n",
        "- Clear prompts and tools like Google Colab and the OpenAI API simplify complex filtering tasks.\n",
        "\n",
        "- Structured outputs (e.g., JSON) and controlled parameters (temperature=0) ensure consistency and ease of integration.\n",
        "\n",
        "- Include manual classification options for cases where automated methods fall short.\n"
      ],
      "metadata": {
        "id": "v54nK1JNoi_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Scholar publication extraction & ABDC ranking analysis\n",
        "\n",
        "This script automates the extraction of publication details from Google Scholar content and evaluates them against the ABDC Journal Rankings. It processes scholarly content, extracts metadata, and performs ranking analysis to assess journal quality.\n",
        "\n",
        "### Key Features:\n",
        "- Extract publication titles, outlet names, and publication years from input text.\n",
        "- Use GPT-4o to structure extracted data into JSON format.\n",
        "- Compare extracted journals against the ABDC database to classify them by ranking (A\\*, A, B, C).\n",
        "- Load data from JSON and Excel files for systematic ranking analysis.\n",
        "- Output matched/unmatched journals, ranking distribution, and validation checks."
      ],
      "metadata": {
        "id": "8doyDctIbzLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# File paths for Google Colab\n",
        "JSON_PATH = \"/content/drive/MyDrive/Teaching/Scholar/scholar_publications.json\"\n",
        "MARKDOWN_PATH = \"/content/drive/MyDrive/Teaching/Scholar/ABDC_Q.md\"\n",
        "\n",
        "class ScholarAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.scholar_content = None\n",
        "        self.json_result = None\n",
        "        self.publications = []\n",
        "\n",
        "    def get_user_input(self):\n",
        "        \"\"\"Display text area for Google Scholar content\"\"\"\n",
        "        text_area = widgets.Textarea(\n",
        "            placeholder='Paste Google Scholar content here...',\n",
        "            description='Scholar Content:',\n",
        "            layout={'width': '100%', 'height': '300px'}\n",
        "        )\n",
        "        button = widgets.Button(description=\"Process Scholar Content\")\n",
        "\n",
        "        display(text_area)\n",
        "        display(button)\n",
        "\n",
        "        def on_button_clicked(b):\n",
        "            self.scholar_content = text_area.value.strip()\n",
        "            if not self.scholar_content:\n",
        "                print(\"Error: No content provided\")\n",
        "                return\n",
        "\n",
        "            button.description = \"Processing...\"\n",
        "            button.disabled = True\n",
        "\n",
        "            # Process the content\n",
        "            self.process_scholar_content()\n",
        "\n",
        "        button.on_click(on_button_clicked)\n",
        "\n",
        "    def process_scholar_content(self):\n",
        "        \"\"\"Process Google Scholar content using OpenAI API\"\"\"\n",
        "        print(\"Processing Google Scholar content...\")\n",
        "\n",
        "        try:\n",
        "            client = OpenAI(api_key=api_key)\n",
        "\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"Extract publications information from a Google Scholar page content and output in JSON format. Each publication should include the outlet name, article title, and publication year. Additionally, calculate and include the total number of publications.\\n\\nOutput Format:\\n- JSON object with two fields:\\n  - \\\"Publications\\\": A JSON list of objects, each with three fields: \\\"Outlet_Name\\\", \\\"Article_Title\\\", and \\\"Publication_Year\\\".\\n  - \\\"Total_Publications\\\": A number representing the total count of publications.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": self.scholar_content\n",
        "                    }\n",
        "                ],\n",
        "                response_format={\"type\": \"text\"},\n",
        "                temperature=0,\n",
        "                max_tokens=16383\n",
        "            )\n",
        "\n",
        "            response_content = response.choices[0].message.content.strip()\n",
        "\n",
        "            # Clean the JSON response\n",
        "            if response_content.startswith(\"```json\"):\n",
        "                response_content = response_content[7:]\n",
        "            if response_content.endswith(\"```\"):\n",
        "                response_content = response_content[:-3]\n",
        "\n",
        "            response_content = response_content.strip()\n",
        "\n",
        "            try:\n",
        "                self.json_result = json.loads(response_content)\n",
        "                print(f\"Successfully extracted {self.json_result.get('Total_Publications', 0)} publications\")\n",
        "\n",
        "                # Display JSON preview\n",
        "                print(\"\\nJSON Preview:\")\n",
        "                display(JSON(self.json_result))\n",
        "\n",
        "                # Save the result\n",
        "                self.save_json_result()\n",
        "\n",
        "                # Continue to ABDC analysis\n",
        "                self.analyze_abdc_rankings()\n",
        "\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error parsing JSON: {str(e)}\")\n",
        "                print(\"Raw response:\\n\", response_content[:500] + \"...\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing content: {str(e)}\")\n",
        "\n",
        "    def save_json_result(self):\n",
        "        \"\"\"Save JSON results to file\"\"\"\n",
        "        try:\n",
        "            # Ensure directory exists\n",
        "            os.makedirs(os.path.dirname(JSON_PATH), exist_ok=True)\n",
        "\n",
        "            with open(JSON_PATH, 'w', encoding='utf-8') as f:\n",
        "                json.dump(self.json_result, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "            print(f\"Results saved to {JSON_PATH}\")\n",
        "\n",
        "            # Verify file exists\n",
        "            if os.path.exists(JSON_PATH):\n",
        "                print(\"File verification successful ✓\")\n",
        "            else:\n",
        "                print(\"Warning: File not found after saving!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving JSON: {str(e)}\")\n",
        "\n",
        "    def load_publications(self):\n",
        "        \"\"\"Load publications from JSON file\"\"\"\n",
        "        try:\n",
        "            with open(JSON_PATH, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "                self.publications = data.get('Publications', [])\n",
        "                print(f\"Loaded {len(self.publications)} publications from file\")\n",
        "                return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading publications: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def load_abdc_rankings(self):\n",
        "        \"\"\"Load ABDC rankings from Markdown file\"\"\"\n",
        "        try:\n",
        "            # Read the markdown file\n",
        "            with open(MARKDOWN_PATH, 'r', encoding='utf-8') as f:\n",
        "                markdown_content = f.read()\n",
        "\n",
        "            # Parse markdown table content\n",
        "            # Assuming the markdown file contains a table with pipe separators\n",
        "            lines = markdown_content.strip().split('\\n')\n",
        "\n",
        "            # Skip header and separator lines\n",
        "            data_lines = [line for line in lines if '|' in line]\n",
        "            if len(data_lines) > 2:  # Ensure we have header, separator, and at least one data row\n",
        "                data_lines = data_lines[2:]  # Skip header and separator rows\n",
        "\n",
        "            # Create dataframe\n",
        "            journal_data = []\n",
        "            for line in data_lines:\n",
        "                cells = [cell.strip() for cell in line.split('|')]\n",
        "                cells = [cell for cell in cells if cell]  # Remove empty cells from edges\n",
        "                if len(cells) >= 2:  # Ensure we have at least journal name and ranking\n",
        "                    journal_data.append({\n",
        "                        'Journal_Name': cells[0],\n",
        "                        'Ranking': cells[1]\n",
        "                    })\n",
        "\n",
        "            df = pd.DataFrame(journal_data)\n",
        "\n",
        "            # Clean and standardize journal names and rankings\n",
        "            df['Journal_Name'] = df['Journal_Name'].str.lower().str.strip()\n",
        "            df['Ranking'] = df['Ranking'].str.strip()\n",
        "\n",
        "            print(f\"Loaded {len(df)} ABDC journal entries from markdown file\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading ABDC rankings from markdown: {str(e)}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def save_analysis_to_markdown(self, results):\n",
        "        \"\"\"Save analysis results to markdown file\"\"\"\n",
        "        try:\n",
        "            output_path = \"/content/drive/MyDrive/Teaching/Scholar/Analysis_results.md\"\n",
        "\n",
        "            summary = results['Summary']\n",
        "            matched_journals = sorted(\n",
        "                results['Matched_Journals'],\n",
        "                key=lambda x: (x['Ranking'], -int(x['Year']) if str(x['Year']).isdigit() else 0)\n",
        "            )\n",
        "            unmatched_journals = sorted(\n",
        "                results['Unmatched_Journals'],\n",
        "                key=lambda x: -int(x['Year']) if str(x['Year']).isdigit() else 0\n",
        "            )\n",
        "\n",
        "            with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                # Title\n",
        "                f.write(\"# ABDC Rankings Analysis\\n\\n\")\n",
        "\n",
        "                # Date\n",
        "                from datetime import datetime\n",
        "                current_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                f.write(f\"*Analysis generated on: {current_date}*\\n\\n\")\n",
        "\n",
        "                # Summary section\n",
        "                f.write(\"## Summary\\n\\n\")\n",
        "                f.write(\"| Category | Count |\\n\")\n",
        "                f.write(\"|----------|------:|\\n\")\n",
        "                f.write(f\"| Total Publications | {summary['Total_Publications']} |\\n\")\n",
        "                f.write(f\"| ABDC Listed Publications | {summary['Total_ABDC']} |\\n\")\n",
        "                f.write(f\"| A* Publications | {summary['A*']} |\\n\")\n",
        "                f.write(f\"| A Publications | {summary['A']} |\\n\")\n",
        "                f.write(f\"| B Publications | {summary['B']} |\\n\")\n",
        "                f.write(f\"| C Publications | {summary['C']} |\\n\")\n",
        "                f.write(f\"| Non-ABDC Publications | {summary['Non_ABDC']} |\\n\\n\")\n",
        "\n",
        "                # Matched journals section\n",
        "                f.write(\"## ABDC Matched Publications\\n\\n\")\n",
        "\n",
        "                # Group by ranking\n",
        "                current_ranking = None\n",
        "                for journal in matched_journals:\n",
        "                    if current_ranking != journal['Ranking']:\n",
        "                        current_ranking = journal['Ranking']\n",
        "                        f.write(f\"### {current_ranking} Ranked Publications\\n\\n\")\n",
        "\n",
        "                    f.write(f\"**{journal['Year']} - {journal['Journal']}**\\n\\n\")\n",
        "                    f.write(f\"{journal['Title']}\\n\\n\")\n",
        "\n",
        "                # Unmatched journals section\n",
        "                f.write(\"## Non-ABDC Publications\\n\\n\")\n",
        "                for journal in unmatched_journals:\n",
        "                    f.write(f\"**{journal['Year']} - {journal['Journal']}**\\n\\n\")\n",
        "                    f.write(f\"{journal['Title']}\\n\\n\")\n",
        "\n",
        "            print(f\"\\nAnalysis saved to markdown file: {output_path}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving analysis to markdown: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def analyze_abdc_rankings(self):\n",
        "        \"\"\"Analyze publications against ABDC rankings\"\"\"\n",
        "        print(\"\\nAnalyzing publications against ABDC rankings...\")\n",
        "\n",
        "        # If we're coming from JSON processing, use the publications from there\n",
        "        if not self.publications and self.json_result:\n",
        "            self.publications = self.json_result.get('Publications', [])\n",
        "\n",
        "        # Otherwise try to load from file\n",
        "        if not self.publications:\n",
        "            if not self.load_publications():\n",
        "                print(\"No publications to analyze. Please process Google Scholar content first.\")\n",
        "                return\n",
        "\n",
        "        # Load ABDC rankings\n",
        "        rankings_df = self.load_abdc_rankings()\n",
        "        if rankings_df.empty:\n",
        "            print(\"Failed to load ABDC rankings from markdown file\")\n",
        "            return\n",
        "\n",
        "        # Create results structure\n",
        "        results = {\n",
        "            'Total_Publications': len(self.publications),\n",
        "            'Rankings': defaultdict(int, {\n",
        "                'A*': 0, 'A': 0, 'B': 0, 'C': 0, 'Non-ABDC': 0\n",
        "            }),\n",
        "            'Matched_Journals': [],\n",
        "            'Unmatched_Journals': []\n",
        "        }\n",
        "\n",
        "        # Create lookup dictionary for faster matching\n",
        "        rankings_lookup = dict(zip(rankings_df['Journal_Name'], rankings_df['Ranking']))\n",
        "\n",
        "        # Match publications with rankings\n",
        "        for pub in self.publications:\n",
        "            matched, ranking = self.find_journal_match(pub['Outlet_Name'], rankings_lookup)\n",
        "\n",
        "            if matched:\n",
        "                # Count the ranking\n",
        "                results['Rankings'][ranking] += 1\n",
        "\n",
        "                # Add to matched journals list\n",
        "                results['Matched_Journals'].append({\n",
        "                    'Journal': pub['Outlet_Name'],\n",
        "                    'Ranking': ranking,\n",
        "                    'Year': pub['Publication_Year'],\n",
        "                    'Title': pub['Article_Title']\n",
        "                })\n",
        "            else:\n",
        "                results['Rankings']['Non-ABDC'] += 1\n",
        "                results['Unmatched_Journals'].append({\n",
        "                    'Journal': pub['Outlet_Name'],\n",
        "                    'Year': pub['Publication_Year'],\n",
        "                    'Title': pub['Article_Title']\n",
        "                })\n",
        "\n",
        "        # Calculate summary statistics\n",
        "        total_abdc = (results['Rankings']['A*'] +\n",
        "                      results['Rankings']['A'] +\n",
        "                      results['Rankings']['B'] +\n",
        "                      results['Rankings']['C'])\n",
        "\n",
        "        results['Summary'] = {\n",
        "            'Total_Publications': results['Total_Publications'],\n",
        "            'Total_ABDC': total_abdc,\n",
        "            'A*': results['Rankings']['A*'],\n",
        "            'A': results['Rankings']['A'],\n",
        "            'B': results['Rankings']['B'],\n",
        "            'C': results['Rankings']['C'],\n",
        "            'Non_ABDC': results['Rankings']['Non-ABDC']\n",
        "        }\n",
        "\n",
        "        # Print the analysis report\n",
        "        self.print_analysis_report(results)\n",
        "\n",
        "    def find_journal_match(self, journal_name, rankings_lookup):\n",
        "        \"\"\"Find if a journal matches any in the ABDC list with 100% match requirement\"\"\"\n",
        "        journal_name_lower = journal_name.lower().strip()\n",
        "\n",
        "        # Try exact match only (case-insensitive)\n",
        "        if journal_name_lower in rankings_lookup:\n",
        "            ranking = rankings_lookup[journal_name_lower].strip()\n",
        "            return True, ranking\n",
        "\n",
        "        # No partial matching or special cases anymore\n",
        "        return False, None\n",
        "\n",
        "    def print_analysis_report(self, results):\n",
        "        \"\"\"Print detailed analysis report and save to markdown file\"\"\"\n",
        "        summary = results['Summary']\n",
        "\n",
        "        # Print to console\n",
        "        print(\"\\nABDC Rankings Analysis:\")\n",
        "        print(\"-----------------------\")\n",
        "        print(f\"Total Publications: {summary['Total_Publications']}\")\n",
        "        print(f\"ABDC Listed Publications: {summary['Total_ABDC']}\")\n",
        "        print(f\"A* Publications: {summary['A*']}\")\n",
        "        print(f\"A Publications: {summary['A']}\")\n",
        "        print(f\"B Publications: {summary['B']}\")\n",
        "        print(f\"C Publications: {summary['C']}\")\n",
        "        print(f\"Non-ABDC Publications: {summary['Non_ABDC']}\")\n",
        "\n",
        "        print(\"\\nMatched ABDC Journals:\")\n",
        "        print(\"----------------------\")\n",
        "        # Sort by ranking and year\n",
        "        matched_journals = sorted(\n",
        "            results['Matched_Journals'],\n",
        "            key=lambda x: (x['Ranking'], -int(x['Year']) if str(x['Year']).isdigit() else 0)\n",
        "        )\n",
        "\n",
        "        # Group by ranking\n",
        "        current_ranking = None\n",
        "        for journal in matched_journals:\n",
        "            if current_ranking != journal['Ranking']:\n",
        "                current_ranking = journal['Ranking']\n",
        "                print(f\"\\n{current_ranking} Ranked Publications:\")\n",
        "                print(\"-\" * (len(current_ranking) + 20))\n",
        "\n",
        "            print(f\"{journal['Year']} - {journal['Journal']}\")\n",
        "            print(f\"Title: {journal['Title']}\")\n",
        "\n",
        "        print(\"\\nUnmatched Journals:\")\n",
        "        print(\"-----------------\")\n",
        "        unmatched_journals = sorted(\n",
        "            results['Unmatched_Journals'],\n",
        "            key=lambda x: -int(x['Year']) if str(x['Year']).isdigit() else 0\n",
        "        )\n",
        "        for journal in unmatched_journals:\n",
        "            print(f\"{journal['Year']} - {journal['Journal']}\")\n",
        "            print(f\"Title: {journal['Title']}\")\n",
        "\n",
        "        print(\"\\nAnalysis complete!\")\n",
        "\n",
        "        # Save to markdown file\n",
        "        self.save_analysis_to_markdown(results)\n",
        "\n",
        "# Run the analyzer\n",
        "analyzer = ScholarAnalyzer()\n",
        "\n",
        "# Option to run just the ABDC analysis (if JSON file already exists)\n",
        "run_only_analysis = False  # Set to True to skip Scholar content extraction\n",
        "\n",
        "if run_only_analysis:\n",
        "    analyzer.analyze_abdc_rankings()\n",
        "else:\n",
        "    analyzer.get_user_input()"
      ],
      "metadata": {
        "id": "HthrCBmbVWuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next: Develop a custom multi-agent system for your work"
      ],
      "metadata": {
        "id": "9MOSxqscxvWI"
      }
    }
  ]
}